{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "abstractive_summary.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP/ZnUdPtqOprmteRDvSMW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0xdferraz/Saense-PLN/blob/main/abstractive_summary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0xdferraz/Saense-PLN ( https://github.com/0xdferraz/Saense-PLN )**\n",
        "\n",
        "\"mT5_multilingual_XLSum\" por csebuetnlp, disponível em: https://huggingface.co/csebuetnlp/mT5_multilingual_XLSum"
      ],
      "metadata": {
        "id": "GMXQVJbwzc7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intruções:**\n",
        "\n",
        "*   Faça upload da pasta contendo os artigos extraídos com o algoritmo \"handle_site.py\"\n",
        "*   Crie uma pasta chamada \"resumos\"\n",
        "*   Execute o algoritmo\n",
        "*   Opcional: Ao final você pode criar uma pasta chamada \"zip\" e executar a seguinte linha: ``` !zip -r zip/resumos.zip resumos/ ```. Assim, será mais fácil baixar os resultados.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e9oFx-MJnPJQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDOM83dlMkS1"
      },
      "outputs": [],
      "source": [
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "1ohfpFpdMmlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import glob\n",
        "import os"
      ],
      "metadata": {
        "id": "A7z4jaT8MnwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))"
      ],
      "metadata": {
        "id": "e3Q80SRcMnr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "TyYOQ1EJMnmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in glob.glob(\"artigos/*.txt\"):\n",
        "  if file != \"artigos/__controle.txt\":\n",
        "    f = open(file,'r',encoding = 'utf-8')\n",
        "    article_text = f.read()\n",
        "    article_name = str(file).split('/')[-1]\n",
        "    length = len(article_text)\n",
        "\n",
        "    input_ids = tokenizer(\n",
        "        [WHITESPACE_HANDLER(article_text)],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=512\n",
        "    )[\"input_ids\"]\n",
        "\n",
        "    output_ids = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=84,\n",
        "        no_repeat_ngram_size=2,\n",
        "        num_beams=4\n",
        "    )[0]\n",
        "\n",
        "    summary = tokenizer.decode(\n",
        "        output_ids,\n",
        "        skip_special_tokens=True,\n",
        "        clean_up_tokenization_spaces=False\n",
        "    )\n",
        "\n",
        "\n",
        "    nomearquivo = \"Summary_\" + article_name\n",
        "    nomecompleto = os.path.join(\"./resumos\", nomearquivo)\n",
        "    f = open(nomecompleto, \"w\")\n",
        "    f.write(summary)\n",
        "    f.close()\n"
      ],
      "metadata": {
        "id": "aUdIoIZfMnpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Opcinal ##\n",
        "!zip -r zip/resumos.zip resumos/"
      ],
      "metadata": {
        "id": "Yoa-lVifpR5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}